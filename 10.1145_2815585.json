[{"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "{MetaSpace}", "author": "Misha Sra and Chris Schmandt", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2817802", "doi": "10.1145/2815585.2817802", "ENTRYTYPE": "inproceedings", "ID": "Sra_2015", "abstract": "Most current virtual reality (VR) interactions are mediated by hand-held input devices or hand gestures and they usually display only a partial representation of the user in the synthetic environment. We believe, representing the user as a full avatar that is controlled by natural movements of the person in the real world will lead to a greater sense of presence in VR. Possible applications exist in various domains such as entertainment, therapy, travel, real estate, education, social interaction and professional assistance. In this demo, we present MetaSpace, a virtual reality system that allows co-located users to explore a VR world together by walking around in physical space. Each user's body is represented by an avatar that is dynamically controlled by their body movements. We achieve this by tracking each user's body with a Kinect device such that their physical movements are mirrored in the virtual world. Users can see their own avatar and the other person's avatar allowing them to perceive and act intuitively in the virtual environment."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Methods of 3D Printing Micro-pillar Structures on Surfaces", "author": "Jifei Ou and Chin-Yi Cheng and Liang Zhou and Gershon Dublon and Hiroshi Ishii", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2817812", "doi": "10.1145/2815585.2817812", "ENTRYTYPE": "inproceedings", "ID": "Ou_2015", "abstract": "This work presents a method of 3D printing hair-like structures on both flat and curved surfaces. It allows a user to design and fabricate hair geometry that is smaller than 100 micron. We built a software platform to let one quickly define a hair's angle, thickness, density, and height. The ability to fabricate customized hair-like structures expands the library of 3D-printable shape. We then present several applications to show how the 3D-printed hair can be used for designing toy objects."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Enhanced Motion Robustness from {ToF}-based Depth Sensing Cameras", "author": "Wataru Yamada and Hiroyuki Manabe and Hiroshi Inamura", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2817807", "doi": "10.1145/2815585.2817807", "ENTRYTYPE": "inproceedings", "ID": "Yamada_2015", "abstract": "Depth sensing cameras that can acquire RGB and depth information are being widely used. They can expand and enhance various camera-based applications and are cheap but strong tools for computer human interaction. RGB and depth sensing cameras have quite different key parameters, such as exposure time. We focus on the differences in their motion robustness; the RGB camera has relatively long exposure times while those of ToF (Time-of-flight) based depth sensing camera are relatively short. An experiment on visual tag reading, one typical application, shows that depth sensing cameras can robustly decode moving tags. The proposed technique will yield robust tag reading, indoor localization, and color image stabilization while walking and jogging or even glancing momentarily without requiring any special additional devices."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "{BitDrones}", "author": "Calvin Rubens and Sean Braley and Antonio Gomes and Daniel Goc and Xujing Zhang and Juan Pablo Carrascal and Roel Vertegaal", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2817810", "doi": "10.1145/2815585.2817810", "ENTRYTYPE": "inproceedings", "ID": "Rubens_2015", "abstract": "In this paper, we present BitDrones, a platform for the construction of interactive 3D displays that utilize nano quadcopters as self-levitating tangible building blocks. Our prototype is a first step towards supporting interactive mid-air, tangible experiences with physical interaction techniques through multiple building blocks capable of physically representing interactive 3D data."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Multi-Modal Peer Discussion with {RichReview} on {edX}", "author": "Dongwook Yoon and Piotr Mitros", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2817809", "doi": "10.1145/2815585.2817809", "ENTRYTYPE": "inproceedings", "ID": "Yoon_2015", "abstract": "In this demo, we present RichReview, a multi-modal peer discussion system, implemented as an XBlock in the edX courseware platform. The system brings richness similar to face-to-face communication into online learning at scale. With this demonstration, we discuss the system?s scalable back-end architecture, semantic voice editing user interface, and a future research plan for the profile based group-assignment scheme."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Dranimate", "author": "Ali Momeni and Zachary Rispoli", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2817815", "doi": "10.1145/2815585.2817815", "ENTRYTYPE": "inproceedings", "ID": "Momeni_2015", "abstract": "Dranimate is an interactive animation system that allows users to rapidly and intuitively rig and control animations based on a still image or drawing, using hand gestures. Dranimate combines two complementary methods of shape manipulation: bone-joint-based physics simulation, and the as-rigid-as-possible deformation algorithm. Dranimate also introduces a number of designed interactions that focus the users attention on the animated content, as opposed to computer keyboard or mouse."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "{GaussStarter}", "author": "Rong-Hao Liang and Han-Chih Kuo and Bing-Yu Chen", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2835511", "doi": "10.1145/2815585.2835511", "ENTRYTYPE": "inproceedings", "ID": "Liang_2015", "abstract": "This work presents GaussStarter, a pluggable and tileable analog Hall-sensor grid module for easy and scalable bread- board prototyping. In terms of ease-of-use, the graspable units allow users to easily plug them on or remove them from a breadboard. In terms of scalability, tiling the units on the breadboard can easily expand the sensing area. A software development kit is also provided for designing applications based on this hardware module."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "{RFlow}", "author": "Hisham Bedri and Otkrist Gupta and Andrew Temme and Micha Feigin and Gregory Charvat and Ramesh Raskar", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2817801", "doi": "10.1145/2815585.2817801", "ENTRYTYPE": "inproceedings", "ID": "Bedri_2015", "abstract": "Current user-interaction with optical gesture tracking technologies suffer from occlusions, limiting the functionality to direct line-of-sight. We introduce RFlow, a compact, medium-range interface based on Radio Frequency (RF) that enables camera-free tracking of the position of a moving hand through drywall and other occluders. Our system uses Time of Flight (TOF) RF sensors and speed-based segmentation to localize the hand of a single user with 5cm accuracy (as measured to the closest ground-truth point), enabling an interface which is not restricted to a training set."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Workload Assessment with eye Movement Monitoring Aided by Non-invasive and Unobtrusive Micro-fabricated Optical Sensors", "author": "Carlos C. Cortes Torres and Kota Sampei and Munehiko Sato and Ramesh Raskar and Norihisa Miki", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2817808", "doi": "10.1145/2815585.2817808", "ENTRYTYPE": "inproceedings", "ID": "Cortes_Torres_2015", "abstract": "Mental state or workload of a person are very relevant when the person is executing delicate tasks such as piloting an aircraft, operating a crane because the high level of workload could prevent accomplishing the task and lead to disastrous results. Some frameworks have been developed to assess the workload and determine whether the person is capable of executing a new task. However, such methodologies are applied when the operator finished the task. Another feature that these methodologies share is that are based on paper and pencil tests. Therefore, human-friendly devices that could assess the workload in real time are in high demand. In this paper, we report a wearable device that can correlate physical eye behavior with the mental state for the workload assessment."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Form Follows Function()", "author": "Jun Kato and Masataka Goto", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2817797", "doi": "10.1145/2815585.2817797", "ENTRYTYPE": "inproceedings", "ID": "Kato_2015", "abstract": "During the development of physical computing devices, physical object models and programs for microcontrollers are usually created with separate tools with distinct files. As a result, it is difficult to track the changes in hardware and software without discrepancy. Moreover, the software cannot directly access hardware metrics. Designing hardware interface cannot benefit from the source code information either. This demonstration proposes a browser-based IDE named f3.js that enables development of both as a single JavaScript code base. The demonstration allows audiences to play with the f3.js IDE and showcases example applications such as laser-cut interfaces generated from the same code but with different parameters. Programmers can experience the full feature and designers can interact with preset projects with a mouse or touch to customize laser-cut interfaces. More information is available at http://f3js.org."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Spotlights", "author": "Byungjoo Lee and Antti Oulasvirta", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2817777", "doi": "10.1145/2815585.2817777", "ENTRYTYPE": "inproceedings", "ID": "Lee_2015", "abstract": "This demo presents Spotlights, a technique to facilitate skim reading, or the activity of rapidly comprehending long documents such as webpages or PDFs. Users mainly use continuous rate-based scrolling to skim. However, visual attention fails when scrolling rapidly due to excessive number of objects and brief exposure per object. Spotlights supports continuous scrolling at high speeds. It selects a small number of objects and raises them to transparent overlays (spotlights) in the viewer. Spotlights stay static for a prolonged time and then fade away. The technical contribution is novel method for ?brokering? user?s attentional resources in a way that guarantees sufficient attentional resources for some objects, even at very high scrolling rates. It facilitates visual attention by (1) decreasing the number of objects competing for divided attention and (2) by ensuring sufficient processing time per object."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "{WearWrite}", "author": "Michael Nebeling and Anhong Guo and Alexandra To and Steven Dow and Jaime Teevan and Jeffrey Bigham", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2817782", "doi": "10.1145/2815585.2817782", "ENTRYTYPE": "inproceedings", "ID": "Nebeling_2015", "abstract": "Smartwatches are becoming increasingly powerful, but limited input makes completing complex tasks impractical. Our WearWrite system introduces a new paradigm for enabling a watch user to contribute to complex tasks, not through new hardware or input methods, but by directing a crowd to work on their behalf from their wearable device. WearWrite lets authors give writing instructions and provide bits of expertise and big picture directions from their smartwatch, while crowd workers actually write the document on more powerful devices. We used this approach to write three academic papers, and found it was effective at producing reasonable drafts."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Creating a Mobile Head-mounted Display with Proprietary Controllers for Interactive Virtual Reality Content", "author": "Kunihiro Kato and Homei Miyashita", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2817776", "doi": "10.1145/2815585.2817776", "ENTRYTYPE": "inproceedings", "ID": "Kato_2015", "abstract": "A method to create a mobile head-mounted display (HMD) a proprietary controller for interactive virtual reality (VR) content is proposed. The proposed method uses an interface cartridge printed with a conductive pattern. This allows the user to operate a smartphone by touching on the face of the mobile HMD. In addition, the user can easily create a mobile HMD and interface cartridge using a laser cutter and inkjet printer. Changing the form of the conductive pattern allows the user to create a variety of controllers. The proposed method can realize an environment that can deliver a variety of interactions with VR content."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "{MagPad}", "author": "Ding Xu and Ali Momeni and Eric Brockmeyer", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815740", "doi": "10.1145/2815585.2815740", "ENTRYTYPE": "inproceedings", "ID": "Xu_2015", "abstract": "In this paper, we present a novel near surface augmented reading system that brings digital content to physical papers. Our system allows a collocated mobile phone to provide augmented content based on its position on top of paper. Our system utilizes built-in magnetometer of a smartphone together with six constantly spinning magnets that generate designed patterns of magnetic flux, to detect 2D location of phone and render dynamic interactive content on the smartphone screen. The proposed technique could be implemented on most of mobile platforms without external sensing hardware."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Zensei", "author": "Munehiko Sato and Rohan S. Puri and Alex Olwal and Deepak Chandra and Ivan Poupyrev and Ramesh Raskar", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2817786", "doi": "10.1145/2815585.2817786", "ENTRYTYPE": "inproceedings", "ID": "Sato_2015", "abstract": "As interactions with everyday handheld devices and objects become increasingly common, a more seamless and effortless identification and personalization technique will be essential to an uninterrupted user experience. In this paper, we present Zensei, a user identification and customization system using human body bioimpedance sensing through multiple electrodes embedded into everyday objects. Zensei provides for an uninterrupted user-device personalization experience that is difficult to forge because it uses both the unique physiological and behavioral characteristics of the user. We demonstrate our measurement system in three exemplary device configurations that showcase different levels of constraint via environment-based, whole-body-based, and handheld-based identification scenarios. We evaluated Zensei's classification accuracy among 12 subjects on each configuration over 22 days of collected data and report our promising results."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Scope$\\mathplus$", "author": "Yu-Hsuan Huang and Tzu-Chieh Yu and Pei-Hsuan Tsai and Yu-Xiang Wang and Wan-ling Yang and Ming Ouhyoung", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2817775", "doi": "10.1145/2815585.2817775", "ENTRYTYPE": "inproceedings", "ID": "Huang_2015", "abstract": "During the process of using conventional stereo microscope, users need to move their head away from the eyepieces repeatedly to access more information, such as anatomy structures from atlas. It happens during microsurgery if surgeons want to check patient?s data again. You might lose your target and your concentration after this kind of disruption. To solve this critical problem and to improve the user experience of stereo microscope, we present Scope+, a stereoscopic video see-through augmented reality system. Scope+ is designed for biological procedures, education and surgical training. While performing biological procedures, for example, dissection of a frog, anatomical atlas will show up inside the head mounted display (HMD) overlaid onto the magnified images. For education purpose, the specimens will no longer be silent under Scope+. When their body parts are pointed by a marked stick, related animation or transparent background video will merge with the real object and interact with observers. If surgeons want to improve their techniques of microsurgery, they can practice with Scope+ which provides complete foot pedal control functions identical to standard surgical microscope. Moreover, cooperating with special designed phantom models, this augmented reality system will guide you to perform some key steps of operation, such as Continuous Curvilinear Capsulorhexis in cataract surgery. Video see-through rather than optical see-through technology is adopt by Scope+ system, therefore remote observation via another Scope+ or web applications can be achieved. This feature can not only assist teachers during experiment classes, but also help researchers keep their eyes on the observables after work. Array mode is powered by the motor-driven stage plate which allows users to load multiple samples at the same time. Quick comparison between samples is possible when switching them by the foot pedal."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Adding Body Motion and Intonation to Instant Messaging with Animation", "author": "Weston Gaylord and Vivian Hare and Ashley Ngu", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815741", "doi": "10.1145/2815585.2815741", "ENTRYTYPE": "inproceedings", "ID": "Gaylord_2015", "abstract": "Digital text communication (DTC) has transformed the way people communicate. Static typographical cues like emoticons, punctuation, letter case, and word lengthening (ie. Hellooo?) are regularly employed to convey intonation and affect. However, DTC platforms like instant messaging still suffer from a lack of nonverbal communication cues. This paper introduces an Animated Text Instant Messenger (ATIM), which uses text animations to add another distinct layer of cues to existing plaintext. ATIM builds upon previous research by using kinetic typography in communication. This paper describes the design principles and features of ATIM and discusses how animated text can add more nuanced communication cues of intonation and body motion."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Juggling the Effects of Latency", "author": "Jarrod Knibbe and Hrvoje Benko and Andrew D. Wilson", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815735", "doi": "10.1145/2815585.2815735", "ENTRYTYPE": "inproceedings", "ID": "Knibbe_2015", "abstract": "Projector-camera (pro-cam) systems afford a wide range of interactive possibilities, combining both natural and mixed-reality 3D interaction. However, the latency inherent within these systems can cause the projection to ?slip? from any moving target, so pro-cam systems have typically shied away from truly dynamic scenarios. We explore software-only techniques to reduce latency; considering the best achievable results with widely adopted commodity devices (e.g. 30Hz depth cameras and 60Hz projectors). We achieve 50% projection alignment on objects in free flight (a 34% improvement) and 69% alignment on dynamic human movement (a 40% improvement)."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "{FoldMecha}", "author": "Hyunjoo Oh and Mark D. Gross and Michael Eisenberg", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815734", "doi": "10.1145/2815585.2815734", "ENTRYTYPE": "inproceedings", "ID": "Oh_2015", "abstract": "We present FoldMecha, a computational tool to help non-experts design and build paper mechanical toys. By customizing templates a user can experiment with basic mechanisms, design their own model, print and cut out a folding net to construct the toy. We used the tool to build two kinds of paper automata models: walkers and flowers."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Remot-{IO}", "author": "Xavier Benavides and Judith Amores and Pattie Maes", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815738", "doi": "10.1145/2815585.2815738", "ENTRYTYPE": "inproceedings", "ID": "Benavides_2015", "abstract": "In this paper we present Remot-IO, a system for mobile collaboration and remote assistance around Internet connected devices. The system uses two Head Mounted Displays, cameras and depth sensors to enable a remote expert to be immersed in a local user's point of view and control devices in that user?s environment. The remote expert can provide guidance through the use of hand gestures that appear in real-time in the local user?s field of view as superimposed 3D hands. In addition, the remote expert is able to operate devices in the novice?s environment and bring about physical changes by using the same hand gestures the novice would use. We describe a smart radio where the knobs of the radio can be controlled by local and remote user alike. Moreover, the user can visualize, interact and modify properties of sound waves in real time by using intuitive hand gestures."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Color Sommelier", "author": "KyoungHee Son and Seo Young Oh and Yongkwan Kim and Hayan Choi and Seok-Hyung Bae and Ganguk Hwang", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815736", "doi": "10.1145/2815585.2815736", "ENTRYTYPE": "inproceedings", "ID": "Son_2015", "abstract": "We present Color Sommelier, an interactive color recommendation system based on community-generated color palettes that helps users to choose harmonious colors on the fly. We used an item-based collaborative filtering technique with Adobe Color CC palettes in order to take advantage of their ratings that reflect the general public?s color harmony preferences. Every time a user chooses a color(s), Color Sommelier calculates how harmonious each of the remaining colors is with the chosen color(s). This interactive recommendation enables users to choose colors iteratively until they are satisfied. To illustrate the usefulness of the algorithm, we implemented a coloring application with a specially designed color chooser. With the chooser, users can intuitively recognize the harmony score of each color based on its bubble size and use the recommendations at their discretion. The Color Sommelier algorithm is flexible enough to be applicable to any color chooser in any software package and is easy to implement."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Perspective-dependent Indirect Touch Input for 3D Polygon Extrusion", "author": "Henri Palleis and Julie Wagner and Heinrich Hussmann", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815733", "doi": "10.1145/2815585.2815733", "ENTRYTYPE": "inproceedings", "ID": "Palleis_2015", "abstract": "We present a two-handed indirect touch interaction technique for the extrusion of polygons within a 3D modeling tool that we have built for a horizontal/vertical dual touch screen setup. In particular, we introduce perspective-dependent touch gestures: using several graphical input areas on the horizontal display, the non-dominant hand navigates the virtual camera and thus continuously updates the spatial frame of reference within which the dominant hand performs extrusions with dragging gestures."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "{KickSoul}", "author": "Xavier Benavides and Chang Long Zhu Jin and Pattie Maes and Joseph Paradiso", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815730", "doi": "10.1145/2815585.2815730", "ENTRYTYPE": "inproceedings", "ID": "Benavides_2015", "abstract": "In this paper we present a wearable device that maps natural feet movements into inputs for digital devices. KickSoul consists of an insole with sensors embedded that tracks movements and triggers actions in devices that surround us. We present a novel approach to use our feet as input devices in mobile situations when our hands are busy. We analyze natural feet?s movements and their meaning before activating an action. This paper discusses different applications for this technology as well as the implementation of our prototype."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "{LegionTools}", "author": "Mitchell Gordon and Jeffrey P. Bigham and Walter S. Lasecki", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815729", "doi": "10.1145/2815585.2815729", "ENTRYTYPE": "inproceedings", "ID": "Gordon_2015", "abstract": "We introduce LegionTools, a toolkit and interface for managing large, synchronous crowds of online workers for experiments. This poster contributes the design and implementation of a state-of-the-art crowd management tool, along with a publicly-available, open-source toolkit that future system builders can use to coordinate synchronous crowds of online workers for their systems and studies."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Capacitive Blocks", "author": "Arika Yoshida and Buntarou Shizuki and Jiro Tanaka", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815731", "doi": "10.1145/2815585.2815731", "ENTRYTYPE": "inproceedings", "ID": "Yoshida_2015", "abstract": "We propose a block-stacking system based on capacitance. The system, called Capacitive Blocks, allows users to build 3D models in a virtual space by stacking physical blocks. The construction of the block-stacking system is simple, and fundamental components including physical blocks can be made with a 3D printer. The block is a capacitor that consists of two layers made of conductive plastic filament and between them a layer made of non-conductive plastic filament. In this paper, we present a prototype of this block-stacking system and the mechanism that detects the height of blocks (i.e., the number of stacked blocks) by measuring the capacitance of the stacked blocks, which changes in accordance with the number of stacked blocks."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Haptic-enabled Active Bone-Conducted Sound Sensing", "author": "Yuya Okawa and Kentaro Takemura", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815732", "doi": "10.1145/2815585.2815732", "ENTRYTYPE": "inproceedings", "ID": "Okawa_2015", "abstract": "In this study, we propose active bone-conducted sound sens- ing for estimating a joint angle of a finger and simultaneous use as a haptic interface. For estimating the joint angle, an unnoticeable vibration is input to the finger, and a perceptible vibration is additionally input to the finger for providing hap- tic feedback. The joint angle is estimated by switching the estimation model depending on the haptic feedback and the average error of the estimation is within about seven degree."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "{AirFlip}-Undo", "author": "Keigo Shima and Ryosuke Takada and Kazusa Onishi and Takuya Adachi and Buntarou Shizuki and Jiro Tanaka", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815737", "doi": "10.1145/2815585.2815737", "ENTRYTYPE": "inproceedings", "ID": "Shima_2015", "abstract": "In this work, we use AirFlip to undo text input on mobile touchscreen devices. AirFlip involves a quick double crossing in-air gesture in the boundary surfaces of hover zone of devices that have hover sensing capability. To evaluate the effectiveness of undoing text input with AirFlip, we implemented two QWERTY soft keyboards (AirFlip keyboard and Typical keyboard). With these keyboards, we conducted a user study to investigate the users? workload and to collect subjective opinions. The results show that there is no significant difference in workload between keyboards."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Effective Interactions for Personalizing Spatial Visualizations of Collections", "author": "Kenneth C. Arnold and Krzysztof Z. Gajos", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815727", "doi": "10.1145/2815585.2815727", "ENTRYTYPE": "inproceedings", "ID": "Arnold_2015", "abstract": "Interactive spatial visualizations powered by machine learning will help us explore and understand large collections in meaningful ways, but little is yet known about the design space of interactions. We ran a pilot user study to compare two different interaction techniques: a \"grouping?\" interaction adapted from interactive clustering, and an existing \"positioning?\" interaction. We identified three important dimensions of the interaction design space that inform future design of more intuitive and expressive interactions."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Elastic Cursor and Elastic Edge", "author": "Jinha Lee and Seungcheon Baek", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815726", "doi": "10.1145/2815585.2815726", "ENTRYTYPE": "inproceedings", "ID": "Lee_2015", "abstract": "We present elastic cursor and elastic edge, new interaction techniques for seamless edge-scroll. Through the use of light-weight physical simulations of elastic behavior on interface elements, we can improve precision, usability, and cueing on the use of edge-scroll in scrollable windows or screens, and make experiences more playful and easier to learn."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Fix and Slide", "author": "Kenji Suzuki and Kazumasa Okabe and Ryuki Sakamoto and Daisuke Sakamoto", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815728", "doi": "10.1145/2815585.2815728", "ENTRYTYPE": "inproceedings", "ID": "Suzuki_2015", "abstract": "We present a ?Fix and Slide? technique, which is a concept to use a movable background to place a caret insertion point and to select text on a mobile device. Standard approach to select text on the mobile devices is touching to the text where a user wants to select, and sometimes pop-up menu is displayed and s/he choose ?select? mode and then start to specify an area to be selected. A big problem is that the user?s finger hides the area to select; this is called a \"fat finger problem.\" We use the movable background to navigate a caret. First a user places a caret by tapping on a screen and then moves the background by touching and dragging on a screen. In this situation, the caret is fixed on the screen so that the user can move the background to navigate the caret where the user wants to move the caret. We implement the Fix and Slide technique on iOS device (iPhone) to demonstrate the impact of this text selection technique on small mobile devices."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "{TMotion}", "author": "Sang Ho Yoon and Ke Huo and Karthik Ramani", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815723", "doi": "10.1145/2815585.2815723", "ENTRYTYPE": "inproceedings", "ID": "Yoon_2015", "abstract": "We present TMotion, a self-contained 3D input that enables spatial interactions around mobile using a magnetic sensing technique. Using a single magnetometer from the mobile device, we can track the 3D position of the permanent magnet embedded in the prototype along with an inertial measurement unit. By numerically solving non-linear magnetic field equations with known orientation from inertial measurement unit (IMU), we attain a tracking rate greater than 30Hz based solely on the mobile device computation. We describe the working principle of TMotion and example applications illustrating its capability."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "A Study on Grasp Recognition Independent of Users{\\textquotesingle} Situations Using Built-in Sensors of Smartphones", "author": "Chanho Park and Takefumi Ogawa", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815722", "doi": "10.1145/2815585.2815722", "ENTRYTYPE": "inproceedings", "ID": "Park_2015", "abstract": "There are many hand postures of smartphone according to the users? situations. In order to support appropriate inter-face, it is important to know user?s hand posture. To recognize grasp postures, which is not depend on users? situations, we consider using smartphone?s touchscreen and their built-in gyroscope and accelerometer and use support vector machine (SVM). In order to evaluate our system, we described the result of the experiments when users are using the devices in the room and on the train. We knew that our system could be feasible for personal use only system by improving the information from the accelerometer. We also collected users? data when users are sitting in the room. Results showed that grasp recognition accuracy under 5 and 4 hand postures were 87.7%, 92.4% respectively when training and testing on 6 users."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Graphical Passwords for Older Computer Users", "author": "Nancy J. Carter", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815593", "doi": "10.1145/2815585.2815593", "ENTRYTYPE": "inproceedings", "ID": "Carter_2015", "abstract": "Computers and the internet have been challenging for many computer users over the age of 60. We conducted a survey of older users which revealed that the creation, management and recall of strong text passwords were some of the challenging aspects of modern technology. In practice, this user group based passwords on familiar facts such as family member names, pets, phone numbers and important personal dates. Graphical passwords formed from abstract graphical symbols or anonymous facial images are feasible, but harder for older computers users to grasp and recall. In this paper we describe initial results for our graphical password system based on recognition of culturally-familiar facial images that are age-relevant to the life experiences of older users. Our goals are to design an easy-to-memorize, graphical password system intended specifically for older users, and achieve a level of password entropy comparable to traditional PINs and text passwords. We are also conducting a user study to demonstrate our technique and capture performance and recall metrics for comparison with traditional password systems."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Hand Biometrics Using Capacitive Touchscreens", "author": "Robert Tartz and Ted Gooding", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815721", "doi": "10.1145/2815585.2815721", "ENTRYTYPE": "inproceedings", "ID": "Tartz_2015", "abstract": "Biometric methods for authentication on mobile devices are becoming popular. Some methods such as face and voice biometrics are problematic in noisy mobile environments, while others such as fingerprint require specialized hardware to operate. We present a novel biometric authentication method that uses raw touch capacitance data captured from the hand touching a display. Performance results using a moderate sample size (N = 40) yielded an equal error rate (EER) of 2.5%, while a 1-month longitudinal study using a smaller sample (N = 10) yielded an EER = 2.3%. Overall, our results provide evidence for biometric uniqueness, permanence and user acceptance."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Using Personal Devices to Facilitate Multi-user Interaction with Large Display Walls", "author": "Ulrich von Zadow", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815592", "doi": "10.1145/2815585.2815592", "ENTRYTYPE": "inproceedings", "ID": "von_Zadow_2015", "abstract": "Large display walls and personal devices such as Smartphones have complementary characteristics. While large displays are well-suited to multi-user interaction (potentially with complex data), they are inherently public and generally cannot present an interface adapted to the individual user. However, effective multi-user interaction in many cases depends on the ability to tailor the interface, to interact without interfering with others, and to access and possibly share private data. The combination with personal devices facilitates exactly this. Multi-device interaction concepts enable data transfer and include moving parts of UIs to the personal device. In addition, hand-held devices can be used to present personal views to the user. Our work will focus on using personal devices for true multi-user interaction with interactive display walls. It will cover appropriate interaction techniques as well as the technical foundation and will be validated with corresponding application cases."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Enriching Online Classroom Communication with Collaborative Multi-Modal Annotations", "author": "Dongwook Yoon", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815591", "doi": "10.1145/2815585.2815591", "ENTRYTYPE": "inproceedings", "ID": "Yoon_2015", "abstract": "In massive open online courses, peer discussion is a scalable solution for offering interactive and engaging learning experiences to a large number of students. On the other hand, the quality of communication mediated through online discussion tools, such as discussion forums, is far less expressive than that of face-to-face communication. As a solution, I present RichReview, a multi-modal annotation system through which distant students can exchange ideas using versatile combinations of voice, text, and pointing gestures. A series of lab and deployment studies of RichReview promised that the expressive multimedia mixture and lightweight audio browsing feature help students better understand commentators? intention. For the large-scale deployment, I redesigned RichReview as a web applet in edX?s courseware framework. By deploying the system at scale, I will investigate (1) the optimal group assignment scheme that maximizes overall diversities of group members, (2) educational data mining applications based on user-generated rich discussion data, and (3) the impact of the rich discussion to students? retention of knowledge. Throughout these studies, I will argue that a multi-modal anchored digital document annotation system enables rich online peer discussion at scale."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Daemo", "author": "Snehal (Neil) Gaikwad and Jeff Regino and Aditi Mithal and Adam Ginzberg and Aditi Nath and Karolina R. Ziulkoski and Trygve Cossette and Dilrukshi Gamage and Angela Richmond-Fuller and Ryo Suzuki and Jeerel Herrej{\\'{o}}n and Durim Morina and Kevin Le and Claudia Flores-Saviaga and Haritha Thilakarathne and Kajal Gupta and William Dai and Ankita Sastry and Shirish Goyal and Thejan Rajapakshe and Niki Abolhassani and Angela Xie and Rohit Nistala and Abigail Reyes and Surabhi Ingle and Ver{\\'{o}}nica Jaramillo and Martin God{\\'{\\i}}nez and Walter {\\'{A}}ngel and Carlos Toxtli and Juan Flores and Asmita Gupta and Vineet Sethia and Diana Padilla and Megha Agarwal and Kristy Milland and Kristiono Setyadi and Nuwan Wajirasena and Muthitha Batagoda and Rolando Cruz and James Damon and Divya Nekkanti and Tejas Sarma and Mohamed Saleh and Gabriela Gongora-Svartzman and Alison Cossette and Soroosh Bateni and Gema Toledo Barrera and Alex Pe{\\~{n}}a and Ryan Compton and Deen Aariff and Luis Palacios and Manuela Paula Ritter and Nisha K.K. and Alan Kay and Jana Uhrmeister and Radhika Bhanu and Srivalli Nistala and Milad Esfahani and Elsa Bakiu and Christopher Diemert and Luca Matsumoto and Manik Singh and Krupa Patel and Ranjay Krishna and Geza Kovacs and Rajan Vaish and Saiph Savage and Michael Bernstein and Vishwajeet Narwal and Karan Rajpal", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815739", "doi": "10.1145/2815585.2815739", "ENTRYTYPE": "inproceedings", "ID": "Gaikwad_2015", "abstract": "Crowdsourcing marketplaces provide opportunities for autonomous and collaborative professional work as well as social engagement. However, in these marketplaces, workers feel disrespected due to unreasonable rejections and low payments, whereas requesters do not trust the results they receive. The lack of trust and uneven distribution of power among workers and requesters have raised serious concerns about sustainability of these marketplaces. To address the challenges of trust and power, this paper introduces Daemo, a self-governed crowdsourcing marketplace. We propose a prototype task to improve the work quality and open-governance model to achieve equitable representation. We envisage Daemo will enable workers to build sustainable careers and provide requesters with timely, quality labor for their businesses."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Wait-Learning", "author": "Carrie J. Cai", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815589", "doi": "10.1145/2815585.2815589", "ENTRYTYPE": "inproceedings", "ID": "Cai_2015", "abstract": "Competing priorities in daily life make it difficult for those with a casual interest in learning to set aside time for regular practice. Yet, learning often requires significant time and effort, with repeated exposures to learning material on a recurring basis. Despite the struggle to find time for learning, there are numerous times in a day that are wasted due to micro-waiting. In my research, I develop systems for wait-learning, leveraging wait time for education. Combining wait time with productive work opens up a new class of software systems that overcomes the problem of limited time while addressing the frustration often associated with waiting. My research tackles several challenges in learning and task management, such as identifying which waiting moments to leverage; how to encourage learning unobtrusively; how to integrate learning across a diversity of waiting moments; and how to extend wait-learning to more complex domains. In the development process, I hope to understand how to manage these waiting moments, and describe essential design principles for wait-learning systems."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Supporting Collaborative Innovation at Scale", "author": "Pao Siangliulue", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815588", "doi": "10.1145/2815585.2815588", "ENTRYTYPE": "inproceedings", "ID": "Siangliulue_2015", "abstract": "Emerging online innovation platforms have enabled large groups of people to collaborate and generate ideas together in ways that were not possible before. However, these platforms also introduce new challenges in finding inspiration from a large number of ideas, and coordinating the collective effort. In my dissertation, I address the challenges of large scale idea generation platforms by developing methods and systems for helping people make effective use of each other's ideas, and for orchestrating collective effort to reduce redundancy and increase the quality and breadth of generated ideas."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "{EMG} Sensor-based Two-Hand Smart Watch Interaction", "author": "Yoonsik Yang and Seungho Chae and Jinwook Shim and Tack-Don Han", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815724", "doi": "10.1145/2815585.2815724", "ENTRYTYPE": "inproceedings", "ID": "Yang_2015", "abstract": "These days, smart watches have drawn more attention of users, and many smart watch products have been launched (Samsung Gear series, apple watch and etc.). Since a smart watch is put on the wrist, the device should be small and unobtrusive. Because of these features, display of the smart watch is small and there is a limitation to interaction. To overcome the limitation, many studies are conducted. In this paper, we propose a two-hand interaction technique that obtains posture information of a hand using electromyography (EMG) sensor attached to the arm and to make input interaction to a smart watch different depending on each posture. EMG sensors recognize information about a user's hand posture, and the non-dominant hand is used for smart watch inputs. In this way, different function is executed depending on postures. As a result, a smart watch that has limited input methods is given a variety of interaction functions with users."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Reconfiguring and Fabricating Special-Purpose Tangible Controls", "author": "Raf Ramakers", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815587", "doi": "10.1145/2815585.2815587", "ENTRYTYPE": "inproceedings", "ID": "Ramakers_2015", "abstract": "Unlike regular interfaces on touch screens or desktop computers, tangible user interfaces allow for more physically rich interactions that better uses the capacity of our motor system. On the flipside, the physicality of tangibles comes with rigidity. This makes it hard to (1) use tangibles on systems that require a variety of controls and interaction styles, and (2) make changes to physical interfaces once manufactured. In my research, I explore techniques that allow users to reconfigure and fabricate tangible interfaces in order to mitigate these issues."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Responsive Facilitation of Experiential Learning Through Access to Attentional State", "author": "Scott W. Greenwald", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815586", "doi": "10.1145/2815585.2815586", "ENTRYTYPE": "inproceedings", "ID": "Greenwald_2015", "abstract": "The planned thesis presents a vision of the future of learning, where learners explore environments, physical and virtual, in a curiosity-driven or intrinsically motivated way, and receive contextual information from a companion facilitator or teacher. Learners are instrumented with sensors that convey their cognitive and attentional state to the companion, who can then accurately judge what is interesting or relevant, and when is a good moment to jump in. I provide a broad definition of the possible types of sensor input as well as the modalities of intervention, and then present a specific proof-of-concept system that uses gaze behavior as a means of communication between the learner and a human companion."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "From Papercraft to Paper Mechatronics", "author": "Hyunjoo Oh", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815590", "doi": "10.1145/2815585.2815590", "ENTRYTYPE": "inproceedings", "ID": "Oh_2015", "abstract": "Paper Mechatronics is a novel interdisciplinary design medium, enabled by recent advances in craft technologies: the term refers to a reappraisal of traditional papercraft in combination with accessible mechanical, electronic, and computational elements. I am investigating the design space of paper mechatronics as a new hands-on medium by developing a series of examples and building a computational tool, FoldMecha, to support non-experts to design and construct their own paper mechatronics models. This paper describes how I used the tool to create two kinds of paper mechatronics models: walkers and flowers and discuss next steps."}, {"booktitle": "Proceedings of the 28th Annual {ACM} Symposium on User Interface Software {\\&} Technology - {UIST} {\\textquotesingle}15 Adjunct", "title": "Investigating the \"Wisdom of Crowds\" at Scale", "author": "Alok Shankar Mysore and Mayank Pahadia and Tushar Dobha and Atif Ahmed and Mani Shankar and Himani Agarwal and Rajat Agarwal and Sai Anirudh-Kondaveeti and Shashank Arun-Gokhale and Aayush Attri and Arpita Chandra and Vikas S. Yaligar and Yogitha Chilukur and Sharath Dharmaji and Deepak Garg and Naman Gupta and Paras Gupta and Glincy Mary Jacob and Siddharth Jain and Shashank Joshi and Tarun Khajuria and Sameeksha Khillan and Imanol Arrieta Ibarra and Sandeep Konam and Praveen Kumar-Kolla and Sahil Loomba and Rachit Madan and Akshansh Maharaja and Vidit Mathur and Bharat Munshi and Mohammed Nawazish and Venkata Neehar-Kurukunda and Venkat Nirmal-Gavarraju and Camelia Simoiu and Sonali Parashar and Harsh Parikh and Avinash Paritala and Amit Patil and Rahul Phatak and Mandar Pradhan and Abhilasha Ravichander and Krishna Sangeeth and Sreecharan Sankaranarayanan and Vibhor Sehgal and Sharad Goel and Ashrith Sheshan, and Suprajha Shibiraj and Aditya Singh and Anjali Singh and Prashant Sinha and Pushkin Soni and Bipin Thomas and Kasyap Varma-Dattada and Sukanya Venkataraman and Pulkit Verma and Ramesh Arvind and Ishan Yelurwar and Chiraag Sumanth and Arvind Srikantan and Bhargav HS", "publisher": "{ACM} Press", "year": "2015", "url": "https://doi.org/10.1145%2F2815585.2815725", "doi": "10.1145/2815585.2815725", "ENTRYTYPE": "inproceedings", "ID": "Shankar_Mysore_2015", "abstract": "In a variety of problem domains, it has been observed that the aggregate opinions of groups are often more accurate than those of the constituent individuals, a phenomenon that has been termed the \"wisdom of the crowd.\" Yet, perhaps surprisingly, there is still little consensus on how generally the phenomenon holds, how best to aggregate crowd judgements, and how social influence affects estimates. We investigate these questions by taking a meta wisdom of crowds approach. With a distributed team of over 100 student researchers across 17 institutions in the United States and India, we develop a large-scale online experiment to systematically study the wisdom of crowds effect for 1,000 different tasks in 50 subject domains. These tasks involve various types of knowledge (e.g., explicit knowledge, tacit knowledge, and prediction), question formats (e.g., multiple choice and point estimation), and inputs (e.g., text, audio, and video). To examine the effect of social influence, participants are randomly assigned to one of three different experiment conditions in which they see varying degrees of information on the responses of others. In this ongoing project, we are now preparing to recruit participants via Amazon?s Mechanical Turk."}]